## Future Computing Technology Assessment

Technology assessment initiatives at SURFsara within [**SURF Open Innovation Lab**](https://www.surf.nl/en/the-surf-cooperative/surf-open-innovation-lab) has a clear goal of understanding the performance of numerous HPC and AI workloads on upcoming computing technologies with a focus on performance analysis, collaboration and open sharing of results. 

As a HPC center, we help researchers to solve challenges associated with their applications on our infrastructure. In this particular initiative, we focus on evaluating, assessing, and benchmarking modern and emerging computing architectures for several application domains such as high performance computing, machine Learning and data visualisation. We have identified four major dimensions of effort. 

1. Consistent, Reproducible and Open benchmarking.
2. Access to the latest compute resources for external and internal users. 
3. Management and professional administration of  experimental compute resources, with easy access and provisioning for external parties. 
4. Knowledge dissemination through workshops and the development of innovative HPC services.



### Open Benchmarking

Here the focus is on aggregrating several relevant benchmarks to standardised compilation, execution and results extraction in a common framework. The idea is to spend less time organising benchmarks and more time in designing exeuction and qualitative analysis of new computing systems making the process of benchmarking more reproducible, open and community engaging.
	
We are using [**Reframe**](https://github.com/eth-cscs/reframe), a HPC regression testing framework from [**CSCS**](https://www.cscs.ch) to automate the process of benchmarking new systems and compute architectures. 
	
<Diagram to explain>

### Access to experimental compute resources

